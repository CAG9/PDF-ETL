{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula\n",
    "import os\n",
    "import glob\n",
    "import pandas\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import pyodbc\n",
    "from datetime import datetime   \n",
    "\n",
    "import database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER = database.USER\n",
    "PASSWORD = database.PASSWORD\n",
    "SERVER = database.SERVER\n",
    "DATABASE = database.DATABASE\n",
    "TBL = database.TABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this hypothetical scenario we have a new daily pdf, we are sure that the table always has this structure.\n",
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](PDFspreadsheet.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfiles(path):\n",
    "    pdfs = []\n",
    "    for file in glob.glob(f\"{path}*.pdf\"):\n",
    "        pdfs.append(file)\n",
    "    return pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracttables(pdfs):\n",
    "    for pdf in pdfs:\n",
    "        tables = tabula.read_pdf(pdf, pages=\"all\")\n",
    "    return tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(path):\n",
    "    pdfs = readfiles(path)\n",
    "    tables = extracttables(pdfs)\n",
    "    return tables\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renamecolumns(tables):\n",
    "    for table in tables:\n",
    "        old_cols = list(table.columns)\n",
    "        new_col0 = ''.join(table.iloc[[0,1],0].values).lower()\n",
    "        new_col1 = ''.join(table.iloc[[0,1],1].values).split('(')[0].lower()\n",
    "        new_col2 = ''.join(table.iloc[[0,1],2].values).split('(')[0].lower()\n",
    "        new_col3 = ''.join(table.iloc[[1,2],3].values).lower()\n",
    "        new_col5 = ''.join(table.iloc[[1,2],5].values).lower()\n",
    "        table.rename(columns={old_cols[0] : new_col0,\n",
    "                           old_cols[1] : new_col1,\n",
    "                           old_cols[2] : new_col2,\n",
    "                           old_cols[3] : new_col3,\n",
    "                           old_cols[5] : new_col5},inplace = True)\n",
    "\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitcolumn(tables):\n",
    "    new_tables = []\n",
    "    for table in tables:\n",
    "        new_cols = table['Percent Fuel Savings'].str.split(' ', expand=True)\n",
    "        old_cols = list(new_cols.columns)\n",
    "        new_col0 = ''.join(new_cols.iloc[[1,2],0].values).lower()\n",
    "        new_col1 = ''.join(new_cols.iloc[[1,2],1].values).lower()\n",
    "        new_cols.rename(columns={old_cols[0] : new_col0,\n",
    "                       old_cols[1] : new_col1},inplace = True)\n",
    "        table.drop(table.columns[[4]],axis = 1,inplace = True)\n",
    "        table = table.join(new_cols)\n",
    "        table = table[['cyclename', 'ki', 'distance', 'improvedspeed', 'decreasedaccel',\n",
    "                                   'eliminatestops','decreasedidle']]\n",
    "        new_tables.append(table)\n",
    "\n",
    "    return new_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removerows(tables):\n",
    "    new_tables = []\n",
    "    for table in tables:\n",
    "        table = table.iloc[3:,:]\n",
    "        new_tables.append(table)\n",
    "    return new_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remocecharacter(tables):\n",
    "    new_tables = []\n",
    "    for table in tables:\n",
    "        for col in table.columns[3:]:\n",
    "            table[col] = table[col].map(lambda x: str(x).replace('%',''))\n",
    "        new_tables.append(table)\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addDate(tables):\n",
    "    new_tables = []\n",
    "    for table in tables:\n",
    "        today = datetime.now()\n",
    "        today.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        table['date'] = today\n",
    "        new_tables.append(table)\n",
    "    return new_tables\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(tables):\n",
    "    tables = renamecolumns(tables)\n",
    "    tables = splitcolumn(tables)\n",
    "    tables = removerows(tables)\n",
    "    tables = remocecharacter(tables)\n",
    "    tables = addDate(tables)\n",
    "    \n",
    "    return tables\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(tables):\n",
    "    try:\n",
    "        rows_imported = 0\n",
    "        engine = create_engine(f\"mysql+pymysql://{USER}:{PASSWORD}@{SERVER}/{DATABASE}\")\n",
    "        for table in tables:\n",
    "            print(f'Importing rows {rows_imported} to {rows_imported + len(table)} ... for table {TBL}')\n",
    "            # Save df to mysql\n",
    "            table.to_sql(TBL, engine, if_exists = 'append', index = False)\n",
    "            rows_imported +- len(table)\n",
    "            # add elapsed time to final print out\n",
    "            print(\"Data imported seccesful\")\n",
    "    except Exception as e:\n",
    "        print('Data load error: '+ str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing rows 0 to 5 ... for table fuel\n",
      "Data imported seccesful\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    path = 'FuelData/'\n",
    "    tables = extract(path)\n",
    "    tables = transform(tables)\n",
    "    load(tables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](db-result.png \"Result\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
